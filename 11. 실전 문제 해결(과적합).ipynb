{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "11. 실전 문제 해결 (과적합).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fIugwpLNeOn",
        "colab_type": "text"
      },
      "source": [
        "# 실전 문제 해결 (과적합)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwVCsNO1NeOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9MYbh6qNeOt",
        "colab_type": "text"
      },
      "source": [
        "## 하이퍼 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KZGbLDvNeOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wz-ddBKNeOw",
        "colab_type": "text"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUaLYJfNeOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvLNReluBlock(tf.keras.Model):  # Layer Normalization\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(ConvLNReluBlock, self).__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
        "    self.ln = tf.keras.layers.LayerNormalization()  # activation은 사용하지 않는다. layer normalazation 이후에 사용.\n",
        "\n",
        "  def call(self, x, training=False, mask=None):\n",
        "    x = self.conv(x)\n",
        "    x = self.ln(x)  # training인지 아닌지 적는 것이 없다. ==> LayerNormalization은 batch의 영향을 받지 않기 때문에 traing과 test에 똑같이 동작을 하기 때문.\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "# Define network architecture\n",
        "class MyModel(tf.keras.Model):  # VGG16 형태\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1_1 = ConvLNReluBlock(16, (3, 3))\n",
        "        self.conv1_2 = ConvLNReluBlock(16, (3, 3))\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
        "\n",
        "        self.conv2_1 = ConvLNReluBlock(32, (3, 3))\n",
        "        self.conv2_2 = ConvLNReluBlock(32, (3, 3))\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
        "\n",
        "        self.conv3_1 = ConvLNReluBlock(64, (3, 3))\n",
        "        self.conv3_2 = ConvLNReluBlock(64, (3, 3))\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))  # l-2 regularizers 사용 lambda = 0.01 적용\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.conv3_2(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYx4_mBoNeO2",
        "colab_type": "text"
      },
      "source": [
        "## 데이터셋 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ae5doQNeO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10  # 32x32x3  ==>  10 class classification\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(1024)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZRTYpeGNeO5",
        "colab_type": "text"
      },
      "source": [
        "## Keras API 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i66IU4k_NeO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e87c3827-76cb-4925-e449-a2ccbe792f09"
      },
      "source": [
        "model = MyModel()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2732 - accuracy: 0.3242 - val_loss: 1.4489 - val_accuracy: 0.5060\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.3121 - accuracy: 0.5702 - val_loss: 1.1681 - val_accuracy: 0.6247\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1187 - accuracy: 0.6460 - val_loss: 1.0261 - val_accuracy: 0.6842\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.0038 - accuracy: 0.6849 - val_loss: 0.9743 - val_accuracy: 0.7010\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.9408 - accuracy: 0.7081 - val_loss: 0.9578 - val_accuracy: 0.7023\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8897 - accuracy: 0.7252 - val_loss: 0.9546 - val_accuracy: 0.7045\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8427 - accuracy: 0.7445 - val_loss: 0.9122 - val_accuracy: 0.7212\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8091 - accuracy: 0.7541 - val_loss: 0.8497 - val_accuracy: 0.7451\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7719 - accuracy: 0.7678 - val_loss: 0.8613 - val_accuracy: 0.7388\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7467 - accuracy: 0.7775 - val_loss: 0.8592 - val_accuracy: 0.7442\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7109 - accuracy: 0.7924 - val_loss: 0.8058 - val_accuracy: 0.7531\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6853 - accuracy: 0.7987 - val_loss: 0.7760 - val_accuracy: 0.7677\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6632 - accuracy: 0.8061 - val_loss: 0.8316 - val_accuracy: 0.7560\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6462 - accuracy: 0.8125 - val_loss: 0.7583 - val_accuracy: 0.7769\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6282 - accuracy: 0.8187 - val_loss: 0.7591 - val_accuracy: 0.7783\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6117 - accuracy: 0.8257 - val_loss: 0.7828 - val_accuracy: 0.7726\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5898 - accuracy: 0.8338 - val_loss: 0.7525 - val_accuracy: 0.7830\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5766 - accuracy: 0.8376 - val_loss: 0.7635 - val_accuracy: 0.7818\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5597 - accuracy: 0.8441 - val_loss: 0.7617 - val_accuracy: 0.7827\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5470 - accuracy: 0.8485 - val_loss: 0.7405 - val_accuracy: 0.7906\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5285 - accuracy: 0.8567 - val_loss: 0.7988 - val_accuracy: 0.7739\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5191 - accuracy: 0.8576 - val_loss: 0.7556 - val_accuracy: 0.7891\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5080 - accuracy: 0.8618 - val_loss: 0.7816 - val_accuracy: 0.7859\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4937 - accuracy: 0.8689 - val_loss: 0.7796 - val_accuracy: 0.7802\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4834 - accuracy: 0.8718 - val_loss: 0.7562 - val_accuracy: 0.7845\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4670 - accuracy: 0.8784 - val_loss: 0.7752 - val_accuracy: 0.7901\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4579 - accuracy: 0.8819 - val_loss: 0.7872 - val_accuracy: 0.7878\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4480 - accuracy: 0.8859 - val_loss: 0.7910 - val_accuracy: 0.7834\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4400 - accuracy: 0.8868 - val_loss: 0.7913 - val_accuracy: 0.7895\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4279 - accuracy: 0.8935 - val_loss: 0.8145 - val_accuracy: 0.7873\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4210 - accuracy: 0.8957 - val_loss: 0.8221 - val_accuracy: 0.7882\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4085 - accuracy: 0.8995 - val_loss: 0.7961 - val_accuracy: 0.7862\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4025 - accuracy: 0.9009 - val_loss: 0.7985 - val_accuracy: 0.7867\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.3970 - accuracy: 0.9038 - val_loss: 0.8107 - val_accuracy: 0.7875\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3854 - accuracy: 0.9073 - val_loss: 0.8441 - val_accuracy: 0.7853\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3818 - accuracy: 0.9103 - val_loss: 0.8270 - val_accuracy: 0.7807\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3765 - accuracy: 0.9116 - val_loss: 0.8541 - val_accuracy: 0.7742\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3645 - accuracy: 0.9159 - val_loss: 0.8890 - val_accuracy: 0.7780\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3554 - accuracy: 0.9185 - val_loss: 0.8858 - val_accuracy: 0.7785\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3486 - accuracy: 0.9218 - val_loss: 0.8654 - val_accuracy: 0.7795\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3468 - accuracy: 0.9223 - val_loss: 0.9440 - val_accuracy: 0.7700\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3377 - accuracy: 0.9248 - val_loss: 0.8980 - val_accuracy: 0.7803\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3320 - accuracy: 0.9279 - val_loss: 0.8868 - val_accuracy: 0.7768\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3246 - accuracy: 0.9313 - val_loss: 0.9218 - val_accuracy: 0.7783\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3230 - accuracy: 0.9317 - val_loss: 0.9059 - val_accuracy: 0.7823\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3172 - accuracy: 0.9344 - val_loss: 0.8848 - val_accuracy: 0.7786\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3165 - accuracy: 0.9349 - val_loss: 0.9626 - val_accuracy: 0.7738\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3080 - accuracy: 0.9357 - val_loss: 0.9095 - val_accuracy: 0.7826\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3048 - accuracy: 0.9373 - val_loss: 0.9689 - val_accuracy: 0.7716\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2987 - accuracy: 0.9411 - val_loss: 0.9662 - val_accuracy: 0.7729\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2916 - accuracy: 0.9427 - val_loss: 0.9265 - val_accuracy: 0.7822\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.2898 - accuracy: 0.9430 - val_loss: 0.9589 - val_accuracy: 0.7786\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2865 - accuracy: 0.9443 - val_loss: 0.9454 - val_accuracy: 0.7788\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2832 - accuracy: 0.9447 - val_loss: 0.9735 - val_accuracy: 0.7732\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2731 - accuracy: 0.9493 - val_loss: 0.9751 - val_accuracy: 0.7738\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2792 - accuracy: 0.9469 - val_loss: 0.9647 - val_accuracy: 0.7825\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2748 - accuracy: 0.9481 - val_loss: 0.9844 - val_accuracy: 0.7805\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2705 - accuracy: 0.9500 - val_loss: 0.9810 - val_accuracy: 0.7770\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2686 - accuracy: 0.9498 - val_loss: 0.9580 - val_accuracy: 0.7804\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2582 - accuracy: 0.9532 - val_loss: 0.9927 - val_accuracy: 0.7684\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2593 - accuracy: 0.9535 - val_loss: 0.9942 - val_accuracy: 0.7733\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2590 - accuracy: 0.9531 - val_loss: 0.9965 - val_accuracy: 0.7729\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2548 - accuracy: 0.9555 - val_loss: 1.0584 - val_accuracy: 0.7656\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2560 - accuracy: 0.9544 - val_loss: 0.9988 - val_accuracy: 0.7719\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2541 - accuracy: 0.9551 - val_loss: 1.0029 - val_accuracy: 0.7841\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2447 - accuracy: 0.9573 - val_loss: 1.0367 - val_accuracy: 0.7807\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2451 - accuracy: 0.9572 - val_loss: 1.1020 - val_accuracy: 0.7617\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2394 - accuracy: 0.9604 - val_loss: 1.0375 - val_accuracy: 0.7765\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.2393 - accuracy: 0.9606 - val_loss: 1.0426 - val_accuracy: 0.7773\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2412 - accuracy: 0.9595 - val_loss: 1.0039 - val_accuracy: 0.7761\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2370 - accuracy: 0.9599 - val_loss: 1.0172 - val_accuracy: 0.7793\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2418 - accuracy: 0.9576 - val_loss: 1.0528 - val_accuracy: 0.7667\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2276 - accuracy: 0.9624 - val_loss: 1.0147 - val_accuracy: 0.7795\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2261 - accuracy: 0.9639 - val_loss: 1.0519 - val_accuracy: 0.7687\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2308 - accuracy: 0.9620 - val_loss: 1.0210 - val_accuracy: 0.7740\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2238 - accuracy: 0.9633 - val_loss: 1.0556 - val_accuracy: 0.7778\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2239 - accuracy: 0.9636 - val_loss: 1.1047 - val_accuracy: 0.7678\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2273 - accuracy: 0.9623 - val_loss: 1.0472 - val_accuracy: 0.7733\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2218 - accuracy: 0.9641 - val_loss: 1.0920 - val_accuracy: 0.7682\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2202 - accuracy: 0.9635 - val_loss: 1.0743 - val_accuracy: 0.7739\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2172 - accuracy: 0.9656 - val_loss: 1.1371 - val_accuracy: 0.7686\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2171 - accuracy: 0.9657 - val_loss: 1.1010 - val_accuracy: 0.7752\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2159 - accuracy: 0.9669 - val_loss: 1.0722 - val_accuracy: 0.7744\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2161 - accuracy: 0.9657 - val_loss: 1.0601 - val_accuracy: 0.7728\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2083 - accuracy: 0.9673 - val_loss: 1.0673 - val_accuracy: 0.7732\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2169 - accuracy: 0.9659 - val_loss: 1.0873 - val_accuracy: 0.7745\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.2070 - accuracy: 0.9689 - val_loss: 1.0693 - val_accuracy: 0.7747\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2080 - accuracy: 0.9681 - val_loss: 1.1050 - val_accuracy: 0.7693\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2048 - accuracy: 0.9688 - val_loss: 1.0767 - val_accuracy: 0.7722\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2068 - accuracy: 0.9680 - val_loss: 1.1027 - val_accuracy: 0.7724\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2020 - accuracy: 0.9695 - val_loss: 1.1041 - val_accuracy: 0.7772\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2001 - accuracy: 0.9714 - val_loss: 1.0869 - val_accuracy: 0.7774\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2010 - accuracy: 0.9692 - val_loss: 1.1302 - val_accuracy: 0.7719\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1993 - accuracy: 0.9697 - val_loss: 1.0933 - val_accuracy: 0.7717\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.2024 - accuracy: 0.9690 - val_loss: 1.1038 - val_accuracy: 0.7720\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1940 - accuracy: 0.9726 - val_loss: 1.1028 - val_accuracy: 0.7766\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1991 - accuracy: 0.9703 - val_loss: 1.0883 - val_accuracy: 0.7797\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1936 - accuracy: 0.9709 - val_loss: 1.0797 - val_accuracy: 0.7712\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1909 - accuracy: 0.9734 - val_loss: 1.2050 - val_accuracy: 0.7668\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1932 - accuracy: 0.9717 - val_loss: 1.0818 - val_accuracy: 0.7802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88c00b85f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8n3Ob7STI7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}